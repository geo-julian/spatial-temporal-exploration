{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named subduction_convergence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b7d414d762f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plate_tectonic_tools_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msubduction_convergence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubduction_convergence_over_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpygplates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named subduction_convergence"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "from parameters import parameters as p\n",
    "import pprint, sys, math, os\n",
    "sys.path.append(p[\"plate_tectonic_tools_path\"])\n",
    "from subduction_convergence import subduction_convergence_over_time\n",
    "import numpy as np\n",
    "import pygplates\n",
    "\n",
    "'''\n",
    "INPUT: 2D array with the following columns\n",
    "    0  longitude\n",
    "    1  latitude \n",
    "    2  subducting convergence (relative to subduction zone) velocity magnitude (in cm/yr)\n",
    "    3  subducting convergence velocity obliquity angle (angle between subduction zone normal \n",
    "        vector and convergence velocity vector)\n",
    "    4  subduction zone absolute (relative to anchor plate) velocity magnitude (in cm/yr)\n",
    "    5  subduction zone absolute velocity obliquity angle (angle between subduction zone normal \n",
    "        vector and absolute velocity vector)\n",
    "    6  length of arc segment (in degrees) that current point is on\n",
    "    7  subducting arc normal azimuth angle (clockwise starting at North, ie, 0 to 360 degrees) at current point\n",
    "    8  subducting plate ID\n",
    "    9  overriding plate ID\n",
    "    10 subduction zone (trench) plate ID\n",
    "    11 subducting plate velocity (vector3D)\n",
    "    12 overriding plate velocity (vector3D)\n",
    "    https://github.com/EarthByte/PlateTectonicTools/blob/master/ptt/subduction_convergence.py\n",
    "    \n",
    "OUTPUT:\n",
    "    0  lon #longitude\n",
    "    1  lat #latitude \n",
    "    2  convergence_velocity_magnitude (convRate) # the magnitude of convergence velocity(cm/yr) \n",
    "    3  arc_length (distance)                     # segmentLength(km) \n",
    "    4  orthogonal_subducting_velocity (orthAbs)  # orthogonal absolute subducting plate velocity \n",
    "    5  orthogonal_overriding_velocity (orthOP)   # orthogonal overriding plate velocity\n",
    "    6  orthogonal_trench_velocity (orthTrench)   # orthogonal trench velocity(cm/yr)\n",
    "    7  subducting_obliquity (subObliquity)       # subducting obliquity(degrees)\n",
    "    8  arc_angle (subPolarity)                   # subducting arc normal azimuth angle(degrees)\n",
    "    9  distEdge                                  # DistanceToSlabEdge(km)\n",
    "    10 orthogonal_convergence_velocity           # orthogonal convergence velocity (cm/yr)\n",
    "    11 parallel_convergence_velocity (convPar)   # parallel convergence velocity (cm/yr)\n",
    "    12 parallel_subducting_velocity (parAbs)     # parallel absolute subducting plate velocity (mm/yr) \n",
    "    13 parallel_overriding_velocity (parOP)      # parallel overriding plate velocity (mm/yr)\n",
    "    14 parallel_trench_velocity (parTrench)      # parallel trench velocity (cm/yr)\n",
    "    15 distEdgeTotal                             # toal Distance To Slab Edge(km)\n",
    "    16 s_pid                                     # subducting plate id\n",
    "    17 trench_pid                                #subduction zone plate id (AKA trench plate id) \n",
    "    18 o_pid                                     #overriding plate id\n",
    "'''\n",
    "def compute_extra_stats(input_data):\n",
    "    ret = []\n",
    "    #get arc vectors from arc normal azimuth angle\n",
    "    arc_vectors = pygplates.LocalCartesian.convert_from_magnitude_azimuth_inclination_to_geocentric(\n",
    "            np.array(input_data)[:,(1,0)], \n",
    "            [(1,x,0) for x in np.array(input_data)[:,7]])\n",
    "    \n",
    "    for idx, row in enumerate(input_data):\n",
    "        subducting_obliquity = pygplates.Vector3D.angle_between(\n",
    "            np.array(row[11].to_xyz()), #subducting plate velocity\n",
    "            np.array(arc_vectors[idx].to_xyz())) #arc vector\n",
    "        \n",
    "        overriding_obliquity = pygplates.Vector3D.angle_between(\n",
    "            np.array(row[12].to_xyz()), #overriding plate velocity\n",
    "            np.array(arc_vectors[idx].to_xyz())) #arc vector\n",
    "        \n",
    "        #######################fill the fields below################\n",
    "        #longitude\n",
    "        lon = row[0]\n",
    "        \n",
    "        #latitude\n",
    "        lat = row[1]\n",
    "        \n",
    "        #the magnitude of convergence velocity(cm/yr) \n",
    "        convergence_velocity_magnitude = row[2] \n",
    "        \n",
    "        #segmentLength(km) \n",
    "        arc_length = np.radians(row[6]) * pygplates.Earth.mean_radius_in_kms\n",
    "        \n",
    "        #orthogonal absolute subducting plate velocity \n",
    "        orthogonal_subducting_velocity = np.dot(\n",
    "            np.array(row[11].to_xyz()),\n",
    "            np.array(row[11].to_xyz())) * math.cos(math.radians(subducting_obliquity))\n",
    "        \n",
    "        #orthogonal overriding plate velocity\n",
    "        orthogonal_overriding_velocity = np.dot(\n",
    "            np.array(row[12].to_xyz()),\n",
    "            np.array(row[12].to_xyz())) * math.cos(math.radians(overriding_obliquity))\n",
    "        \n",
    "        #orthogonal trench velocity(cm/yr)\n",
    "        orthogonal_trench_velocity = row[4] * math.cos(math.radians(row[5]))\n",
    "        \n",
    "        #subducting obliquity(degrees)\n",
    "        subducting_obliquity = row[3]\n",
    "        \n",
    "        #subducting arc normal azimuth angle(degrees)\n",
    "        arc_angle = row[7]\n",
    "        \n",
    "        # DistanceToSlabEdge(km)\n",
    "        distEdge = 0#TODO\n",
    "        \n",
    "        # orthogonal convergence velocity (cm/yr),\n",
    "        orthogonal_convergence_velocity = convergence_velocity_magnitude * math.cos(math.radians(row[3]))\n",
    "        \n",
    "        # parallel convergence velocity (cm/yr)\n",
    "        parallel_convergence_velocity = convergence_velocity_magnitude * math.sin(math.radians(row[3]))\n",
    "        \n",
    "        # Parallel absolute subducting plate velocity (mm/yr) \n",
    "        parallel_subducting_velocity = np.dot(\n",
    "            np.array(row[11].to_xyz()),\n",
    "            np.array(row[11].to_xyz())) * math.cos(math.radians(subducting_obliquity))\n",
    "        \n",
    "        # Parallel overriding plate velocity (mm/yr)\n",
    "        parallel_overriding_velocity = np.dot(\n",
    "            np.array(row[12].to_xyz()),\n",
    "            np.array(row[12].to_xyz())) * math.cos(math.radians(overriding_obliquity))\n",
    "        \n",
    "        # parallel trench velocity (cm/yr)\n",
    "        parallel_trench_velocity = row[4] * math.sin(math.radians(row[5]))\n",
    "        \n",
    "        # toal Distance To Slab Edge(km)\n",
    "        distEdgeTotal = 0#TODO\n",
    "        \n",
    "        #subducting plate id\n",
    "        s_pid = row[8]\n",
    "        \n",
    "        #subduction zone plate id (AKA trench plate id) \n",
    "        trench_pid = row[10]\n",
    "        \n",
    "        #overriding plate id\n",
    "        o_pid = row[9]\n",
    "        \n",
    "        ret.append((lon, lat, convergence_velocity_magnitude, arc_length,\\\n",
    "            orthogonal_subducting_velocity, orthogonal_overriding_velocity,\\\n",
    "            orthogonal_trench_velocity, subducting_obliquity, arc_angle, distEdge,\\\n",
    "            orthogonal_convergence_velocity, parallel_convergence_velocity,\\\n",
    "            parallel_subducting_velocity, parallel_overriding_velocity,\\\n",
    "            parallel_trench_velocity, distEdgeTotal,\\\n",
    "            s_pid, trench_pid, o_pid))\n",
    "    return ret\n",
    " \n",
    "    \n",
    "def append_velocity(stats, pid_index, time, delta_time, rotation_model):\n",
    "    new_stats = []\n",
    "    sorted_stats = sorted(stats, key = lambda x: x[pid_index]) #sort by plate id\n",
    "    from itertools import groupby\n",
    "    for pid, group in groupby(sorted_stats, lambda x: x[pid_index]):  #group by plate id\n",
    "        #print pid\n",
    "        grouped_stats = [x for x in group]\n",
    "        points = np.array(grouped_stats)[:,(1,0)]\n",
    "        rotation = rotation_model.get_rotation(time, pid, time + delta_time, anchor_plate_id=0)\n",
    "        velocities = pygplates.calculate_velocities(\n",
    "            points, rotation, delta_time, pygplates.VelocityUnits.cms_per_yr)\n",
    "        #print(np.array(velocities).shape)\n",
    "        for i in range(len(grouped_stats)):\n",
    "            new_stats.append(grouped_stats[i] + tuple([velocities[i]]))\n",
    "    \n",
    "    return new_stats\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pp = pprint.PrettyPrinter(indent=2)\n",
    "    pp.pprint(p)  \n",
    "    \n",
    "    kwargs = {    \n",
    "        'output_distance_to_nearest_edge_of_trench':True,\n",
    "        'output_distance_to_start_edge_of_trench':True,\n",
    "        'output_convergence_velocity_components':True,\n",
    "        'output_trench_absolute_velocity_components':True,\n",
    "        'output_subducting_absolute_velocity':True,\n",
    "        'output_subducting_absolute_velocity_components':True}\n",
    "\n",
    "    return_code = subduction_convergence_over_time(\n",
    "            p['convergence_data_filename_prefix'],\n",
    "            p['convergence_data_filename_ext'],\n",
    "            p[\"rotation_files\"],\n",
    "            p[\"topology_files\"],\n",
    "            math.radians(p[\"threshold_sampling_distance_degrees\"]),\n",
    "            p[\"time\"][\"start\"],\n",
    "            p[\"time\"][\"end\"],\n",
    "            p[\"time\"][\"step\"],\n",
    "            p[\"velocity_delta_time\"],\n",
    "            p['anchor_plate_id'],\n",
    "            output_gpml_filename = None,\n",
    "            **kwargs)\n",
    "    \n",
    "    result_dir=p['convergence_data_dir']\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    os.system('mv {0}*{1} {2}'.format( \n",
    "        p['convergence_data_filename_prefix'], p['convergence_data_filename_ext'], result_dir))\n",
    "    print('The result data has been saved in {}!'.format(result_dir))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(ret)\n",
    "print(test.shape)\n",
    "print(np.sum(test[:,13]==test[:,14]))\n",
    "data = test[(test[:,13]==test[:,14])][:,(12,13,14)].astype(int)\n",
    "coords = test[(test[:,13]==test[:,14])][:,(0,1)]\n",
    "result = []\n",
    "for row in zip(coords, data):\n",
    "    result.append((row[0][0],row[0][1],row[1][0],row[1][1],row[1][2]))\n",
    "#print result\n",
    "np.savetxt('pids_same.txt', result, fmt='%1.2f %1.2f %i %i %i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(16,12),dpi=150)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.stock_img()\n",
    "ax.set_extent([-180, 180, -90, 90])\n",
    "\n",
    "c=[]\n",
    "for p in test:\n",
    "    if p[13] == p[14]:\n",
    "        c.append(\"blue\")\n",
    "    else:\n",
    "        c.append(\"red\")\n",
    "\n",
    "lons = test[:,0]\n",
    "lats = test[:,1]\n",
    "plt.scatter(lons,lats,color=c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import scipy.spatial\n",
    "from scipy.signal import decimate\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np\n",
    "import time, math, pickle, os, urllib\n",
    "import pygplates\n",
    "from matplotlib import pyplot as plt\n",
    "import shapefile\n",
    "\n",
    "from parameters import parameters as param\n",
    "\n",
    "# output data\n",
    "# \n",
    "#0 lon\n",
    "#1 lat\n",
    "#2 reconstructed lon \n",
    "#3 reconstructed lat \n",
    "#4 age\n",
    "#5 time\n",
    "#6 age at reconstructed location (from age grid)\n",
    "#7 subducting convergence (relative to trench) velocity magnitude (in cm/yr)\n",
    "#8 subducting convergence velocity obliquity angle (angle between trench normal vector and convergence velocity vector)\n",
    "#9 trench absolute (relative to anchor plate) velocity magnitude (in cm/yr)\n",
    "#10 trench absolute velocity obliquity angle (angle between trench normal vector and trench absolute velocity vector)\n",
    "#11 length of arc segment (in degrees) that current point is on\n",
    "#12 trench normal azimuth angle (clockwise starting at North, ie, 0 to 360 degrees) at current point\n",
    "#13 subducting plate ID\n",
    "#14 trench plate ID\n",
    "#15 distance (in degrees) along the trench line to the nearest trench edge\n",
    "#16 the distance (in degrees) along the trench line from the start edge of the trench\n",
    "#17 convergence velocity orthogonal (in cm/yr)\n",
    "#18 convergence velocity parallel  (in cm/yr) \n",
    "#19 the trench plate absolute velocity orthogonal (in cm/yr)\n",
    "#20 the trench plate absolute velocity orthogonal (in cm/yr)\n",
    "#21 the subducting plate absolute velocity magnitude (in cm/yr)\n",
    "#22 the subducting plate absolute velocityobliquity angle (in degrees)\n",
    "#23 the subducting plate absolute velocity orthogonal       \n",
    "#24 the subducting plate absolute velocity parallel\n",
    "#25 plate id of the input point\n",
    "ROW_LEN = 26\n",
    "\n",
    "def main():\n",
    "    start_time = param[\"time\"][\"start\"]\n",
    "    end_time = param[\"time\"][\"end\"]\n",
    "    time_step =  param[\"time\"][\"step\"]\n",
    "\n",
    "    # input: degrees between two points on sphere\n",
    "    # output: straight distance between the two points (assume the earth radius is 1)\n",
    "    # to get the kilometers, use the return value to multiply by the real earth radius\n",
    "    def degree_to_straight_distance(degree):\n",
    "        return math.sin(math.radians(degree)) / math.sin(math.radians(90 - degree/2.))\n",
    "\n",
    "\n",
    "    # the age is a floating-point number. map the floating-point number to the nereast integer time in the range\n",
    "    def get_time_from_age(ages, start, end, step):\n",
    "        ret=[]\n",
    "        times=range(start, end+1, step)\n",
    "        for age in ages:\n",
    "            if age <= start:\n",
    "                ret.append(start)\n",
    "            elif age >= end:\n",
    "                ret.append(end)\n",
    "            else:\n",
    "                idx = int((age - start)//step)\n",
    "                mod = (age - start)%step\n",
    "                if not (mod < step/2.):\n",
    "                    idx = idx+1 \n",
    "                ret.append(times[idx])\n",
    "\n",
    "        return ret  \n",
    "\n",
    "    # copy the attributes around\n",
    "    def get_attributes(point, data, index):\n",
    "        point[7:25] = data[index, 2:20]\n",
    "\n",
    "    tic=time.time()\n",
    "\n",
    "    region_1 = param['region_1'] #degrees\n",
    "    region_2 = param['region_2'] #degrees\n",
    "\n",
    "    #construct the grid tree\n",
    "    grid_x, grid_y = np.mgrid[-180:181, -90:91]\n",
    "    grid_points = [pygplates.PointOnSphere((row[1],row[0])).to_xyz() for row in zip(grid_x.flatten(), grid_y.flatten())]\n",
    "    grid_tree = scipy.spatial.cKDTree(grid_points)\n",
    "\n",
    "    #load files\n",
    "    f = np.loadtxt(param['convergence_data_dir'] + param['convergence_data_filename_prefix'] \n",
    "                        + \"_0.00.\" + param['convergence_data_filename_ext'])\n",
    "    trench_points=f[(f[:,9])==201]\n",
    "    rotation_model = pygplates.RotationModel(param['rotation_files'])\n",
    "    reader = shapefile.Reader(param['andes_data'])\n",
    "    recs    = reader.records()\n",
    "    andes_points_len = len(recs)\n",
    "    randomAges=np.random.randint(start_time+1, end_time, size=andes_points_len)\n",
    "    times = get_time_from_age(np.array(recs)[:,6], start_time, end_time, time_step)\n",
    "\n",
    "    # create buffer for points\n",
    "    points=np.full((len(trench_points)*len(range(end_time)) + andes_points_len*2, ROW_LEN), float('nan'))\n",
    "\n",
    "    # fill the andes deposit points with the real age\n",
    "    for i in range(andes_points_len):\n",
    "        points[i][0]=recs[i][3] #lon\n",
    "        points[i][1]=recs[i][4] #lat\n",
    "        points[i][4]=recs[i][6] #age\n",
    "        points[i][5]=times[i] #time\n",
    "        points[i][-1]=recs[i][7] #plate id\n",
    "\n",
    "    points_with_age_size=i+1\n",
    "\n",
    "    # fill andes deposit points with random ages\n",
    "    for i in range(andes_points_len): \n",
    "        points[points_with_age_size+i][0]=recs[i][3] #lon\n",
    "        points[points_with_age_size+i][1]=recs[i][4] #lat\n",
    "        points[points_with_age_size+i][4]=randomAges[i] #age\n",
    "        points[points_with_age_size+i][5]=randomAges[i] #time\n",
    "        points[points_with_age_size+i][-1]=recs[i][7] #plate id\n",
    "\n",
    "    points_with_random_age_size=i+1\n",
    "\n",
    "    # fill trench points for each time step from start_time to end_time\n",
    "    start_idx = points_with_age_size + points_with_random_age_size\n",
    "    i=0\n",
    "    for p in trench_points:\n",
    "        for t in range(end_time):\n",
    "            points[start_idx+i][0]=p[0] #lon\n",
    "            points[start_idx+i][1]=p[1] #lat\n",
    "            points[start_idx+i][4]=0 #age\n",
    "            points[start_idx+i][5]=t #time\n",
    "            points[start_idx+i][-1]=201 #plate id\n",
    "            i+=1\n",
    "\n",
    "    poins_all_time_size=i+1 \n",
    "\n",
    "\n",
    "    sorted_points = sorted(points, key = lambda x: int(x[5])) #sort by time\n",
    "    from itertools import groupby\n",
    "    for t, group in groupby(sorted_points, lambda x: int(x[5])):  #group by time\n",
    "        print(t)\n",
    "        age_grid_fn = param['age_grid_dir'] + param['age_grid_prefix'] + str(t) + \".nc\"\n",
    "        if not os.path.isfile(age_grid_fn):\n",
    "            urllib.urlretrieve(param['age_grid_url_prefix']+str(t)+\".nc\", age_grid_fn)\n",
    "\n",
    "        rasterfile = Dataset(age_grid_fn,'r')\n",
    "        z = rasterfile.variables['z'][:] #masked array\n",
    "        z = z[::10,::10] #TODO: make sure the grid is 1 degree by 1 degree\n",
    "        z = z.flatten()\n",
    "\n",
    "        # build the points tree\n",
    "        data=np.loadtxt(param['convergence_data_dir'] + param['convergence_data_filename_prefix'] \n",
    "                        + '_{:0.2f}'.format(t) + \".\" + param['convergence_data_filename_ext']) \n",
    "        \n",
    "        points_3d = [pygplates.PointOnSphere((row[1],row[0])).to_xyz() for row in data]\n",
    "        points_tree = scipy.spatial.cKDTree(points_3d)\n",
    "\n",
    "        # reconstruct the points\n",
    "        rotated_points = []\n",
    "        grouped_points = list(group)\n",
    "        for point in grouped_points:\n",
    "            point_to_rotate = pygplates.PointOnSphere((point[1], point[0]))\n",
    "            finite_rotation = rotation_model.get_rotation(point[5], int(point[-1]))\n",
    "            geom = finite_rotation * point_to_rotate\n",
    "            rotated_points.append(geom.to_xyz())\n",
    "            point[3], point[2] = geom.to_lat_lon()\n",
    "\n",
    "        # query the trees\n",
    "        dists, indices = points_tree.query(\n",
    "            rotated_points, k=1, distance_upper_bound=degree_to_straight_distance(region_1)) \n",
    "        all_neighbors = grid_tree.query_ball_point(\n",
    "                rotated_points, \n",
    "                degree_to_straight_distance(region_1))\n",
    "\n",
    "        # get the attributes, query the tree again if necessary\n",
    "        for point, dist, idx, neighbors in zip(grouped_points, dists, indices, all_neighbors):\n",
    "            if idx < len(data):\n",
    "                get_attributes(point, data, idx)\n",
    "            else:\n",
    "                #try again with a bigger region\n",
    "                dist_2, index_2 = points_tree.query(\n",
    "                    pygplates.PointOnSphere((point[3], point[2])).to_xyz(), \n",
    "                    k=1, \n",
    "                    distance_upper_bound=degree_to_straight_distance(region_2))\n",
    "                if index_2 < len(data):\n",
    "                    get_attributes(point, data, index_2)\n",
    "\n",
    "            if np.sum(~z[neighbors].mask)>0:\n",
    "                point[6] = np.nanmean(z[neighbors])\n",
    "            else: \n",
    "                #try again with a bigger region\n",
    "                neighbors_2 = grid_tree.query_ball_point(\n",
    "                    pygplates.PointOnSphere((point[3], point[2])).to_xyz(), \n",
    "                    degree_to_straight_distance(region_2))\n",
    "                if np.sum(~z[neighbors_2].mask)>0:\n",
    "                    point[6] = np.nanmean(z[neighbors_2])\n",
    "\n",
    "    #print(points)\n",
    "    np.savetxt('./andes_real_age.csv',points[:points_with_age_size], fmt='%.2f')\n",
    "    np.savetxt('./andes_random_age.csv',points[points_with_age_size:points_with_random_age_size+points_with_age_size], fmt='%.2f')\n",
    "    np.savetxt('./trench_points.csv',points[points_with_random_age_size+points_with_age_size:], fmt='%.2f')\n",
    "    toc=time.time()\n",
    "    print(\"Time taken:\", toc-tic, \" seconds\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
